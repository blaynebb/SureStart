{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unsampling.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbHIvAP643hT"
      },
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "# This is the size of our encoded representations\n",
        "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
        "\n",
        "# This is our input image\n",
        "input_img = keras.Input(shape=(784,))\n",
        "# \"encoded\" is the encoded representation of the input\n",
        "encoded = layers.Dense(encoding_dim, activation='relu')(input_img)\n",
        "# \"decoded\" is the lossy reconstruction of the input\n",
        "decoded = layers.Dense(784, activation='sigmoid')(encoded)\n",
        "\n",
        "# This model maps an input to its reconstruction\n",
        "autoencoder = keras.Model(input_img, decoded)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtygePT647Wi"
      },
      "source": [
        "# This model maps an input to its encoded representation\n",
        "encoder = keras.Model(input_img, encoded)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSFUgiQ65AOw"
      },
      "source": [
        "# This is our encoded (32-dimensional) input\n",
        "encoded_input = keras.Input(shape=(encoding_dim,))\n",
        "# Retrieve the last layer of the autoencoder model\n",
        "decoder_layer = autoencoder.layers[-1]\n",
        "# Create the decoder model\n",
        "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYHiKWEm5FQI"
      },
      "source": [
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysZjBVLT5ICt",
        "outputId": "27dbab36-dd34-4034-a09e-3157296ce327"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "(x_train, _), (x_test, _) = mnist.load_data()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rv8pQozJ5LiU",
        "outputId": "5476e96c-1ec3-432a-e385-db12c1dc2cd6"
      },
      "source": [
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQPzELql5NzE",
        "outputId": "016745a1-5e46-4f77-8866-317e568b41ad"
      },
      "source": [
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=50,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "235/235 [==============================] - 4s 13ms/step - loss: 0.3824 - val_loss: 0.1876\n",
            "Epoch 2/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.1781 - val_loss: 0.1526\n",
            "Epoch 3/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.1491 - val_loss: 0.1332\n",
            "Epoch 4/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.1311 - val_loss: 0.1206\n",
            "Epoch 5/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.1196 - val_loss: 0.1125\n",
            "Epoch 6/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.1121 - val_loss: 0.1068\n",
            "Epoch 7/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.1072 - val_loss: 0.1025\n",
            "Epoch 8/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.1030 - val_loss: 0.0995\n",
            "Epoch 9/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.1003 - val_loss: 0.0974\n",
            "Epoch 10/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0982 - val_loss: 0.0957\n",
            "Epoch 11/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0967 - val_loss: 0.0947\n",
            "Epoch 12/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0957 - val_loss: 0.0939\n",
            "Epoch 13/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0949 - val_loss: 0.0934\n",
            "Epoch 14/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0946 - val_loss: 0.0930\n",
            "Epoch 15/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0942 - val_loss: 0.0927\n",
            "Epoch 16/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0939 - val_loss: 0.0927\n",
            "Epoch 17/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0938 - val_loss: 0.0925\n",
            "Epoch 18/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0935 - val_loss: 0.0923\n",
            "Epoch 19/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0935 - val_loss: 0.0922\n",
            "Epoch 20/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0933 - val_loss: 0.0921\n",
            "Epoch 21/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0933 - val_loss: 0.0920\n",
            "Epoch 22/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0932 - val_loss: 0.0920\n",
            "Epoch 23/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0932 - val_loss: 0.0920\n",
            "Epoch 24/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0933 - val_loss: 0.0919\n",
            "Epoch 25/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0931 - val_loss: 0.0918\n",
            "Epoch 26/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0930 - val_loss: 0.0918\n",
            "Epoch 27/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0929 - val_loss: 0.0918\n",
            "Epoch 28/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0929 - val_loss: 0.0919\n",
            "Epoch 29/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0927 - val_loss: 0.0917\n",
            "Epoch 30/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0927 - val_loss: 0.0917\n",
            "Epoch 31/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0929 - val_loss: 0.0917\n",
            "Epoch 32/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0928 - val_loss: 0.0916\n",
            "Epoch 33/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0931 - val_loss: 0.0917\n",
            "Epoch 34/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0929 - val_loss: 0.0916\n",
            "Epoch 35/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0927 - val_loss: 0.0916\n",
            "Epoch 36/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0927 - val_loss: 0.0916\n",
            "Epoch 37/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0929 - val_loss: 0.0915\n",
            "Epoch 38/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0926 - val_loss: 0.0916\n",
            "Epoch 39/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0926 - val_loss: 0.0915\n",
            "Epoch 40/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0927 - val_loss: 0.0916\n",
            "Epoch 41/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0927 - val_loss: 0.0915\n",
            "Epoch 42/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0926 - val_loss: 0.0915\n",
            "Epoch 43/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0925 - val_loss: 0.0915\n",
            "Epoch 44/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0927 - val_loss: 0.0915\n",
            "Epoch 45/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0927 - val_loss: 0.0915\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "QtAmFG2b5PtP",
        "outputId": "28682e72-4ae2-4e42-a38e-ebf223496d12"
      },
      "source": [
        "# Encode and decode some digits\n",
        "# Note that we take them from the *test* set\n",
        "encoded_imgs = encoder.predict(x_test)\n",
        "decoded_imgs = decoder.predict(encoded_imgs)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4a39bc8df7e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Encode and decode some digits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Note that we take them from the *test* set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mencoded_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdecoded_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'encoder' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPlYQ6Mv5R7B"
      },
      "source": [
        "# Use Matplotlib (don't ask)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 10  # How many digits we will display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # Display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LE9QWdvj5UWp"
      },
      "source": [
        "from keras import regularizers\n",
        "\n",
        "encoding_dim = 32\n",
        "\n",
        "input_img = keras.Input(shape=(784,))\n",
        "# Add a Dense layer with a L1 activity regularizer\n",
        "encoded = layers.Dense(encoding_dim, activation='relu',\n",
        "                activity_regularizer=regularizers.l1(10e-5))(input_img)\n",
        "decoded = layers.Dense(784, activation='sigmoid')(encoded)\n",
        "\n",
        "autoencoder = keras.Model(input_img, decoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7oiT6wA5W1P"
      },
      "source": [
        "input_img = keras.Input(shape=(784,))\n",
        "encoded = layers.Dense(128, activation='relu')(input_img)\n",
        "encoded = layers.Dense(64, activation='relu')(encoded)\n",
        "encoded = layers.Dense(32, activation='relu')(encoded)\n",
        "\n",
        "decoded = layers.Dense(64, activation='relu')(encoded)\n",
        "decoded = layers.Dense(128, activation='relu')(decoded)\n",
        "decoded = layers.Dense(784, activation='sigmoid')(decoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6melhoeA5ar7"
      },
      "source": [
        "autoencoder = keras.Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=100,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgKBjk_P5eBl"
      },
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "input_img = keras.Input(shape=(28, 28, 1))\n",
        "\n",
        "x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
        "\n",
        "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "x = layers.Conv2D(16, (3, 3), activation='relu')(x)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = keras.Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_UScX9M5esW"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
        "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFPn0U925hQM"
      },
      "source": [
        "tensorboard --logdir=/tmp/autoencoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPo91kGz5i_v"
      },
      "source": [
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=50,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test),\n",
        "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ag81V-eJ5lPh"
      },
      "source": [
        "decoded_imgs = autoencoder.predict(x_test)\n",
        "\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(1, n + 1):\n",
        "    # Display original\n",
        "    ax = plt.subplot(2, n, i)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Display reconstruction\n",
        "    ax = plt.subplot(2, n, i + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXCiq2oX5p-k"
      },
      "source": [
        "encoder = keras.Model(input_img, encoded)\n",
        "encoded_imgs = encoder.predict(x_test)\n",
        "\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 8))\n",
        "for i in range(1, n + 1):\n",
        "    ax = plt.subplot(1, n, i)\n",
        "    plt.imshow(encoded_imgs[i].reshape((4, 4 * 8)).T)\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJ1ekrNa5sHG"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
        "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))\n",
        "\n",
        "noise_factor = 0.5\n",
        "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
        "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n",
        "\n",
        "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
        "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HItQlTV5s3h"
      },
      "source": [
        "n = 10\n",
        "plt.figure(figsize=(20, 2))\n",
        "for i in range(1, n + 1):\n",
        "    ax = plt.subplot(1, n, i)\n",
        "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2qUMJDy5vBb"
      },
      "source": [
        "input_img = keras.Input(shape=(28, 28, 1))\n",
        "\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# At this point the representation is (7, 7, 32)\n",
        "\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = keras.Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1V8iNBIa5ymX"
      },
      "source": [
        "autoencoder.fit(x_train_noisy, x_train,\n",
        "                epochs=100,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test_noisy, x_test),\n",
        "                callbacks=[TensorBoard(log_dir='/tmp/tb', histogram_freq=0, write_graph=False)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQg--cxy51Cy"
      },
      "source": [
        "timesteps = ...  # Length of your sequences\n",
        "input_dim = ... \n",
        "latent_dim = ...\n",
        "\n",
        "inputs = keras.Input(shape=(timesteps, input_dim))\n",
        "encoded = layers.LSTM(latent_dim)(inputs)\n",
        "\n",
        "decoded = layers.RepeatVector(timesteps)(encoded)\n",
        "decoded = layers.LSTM(input_dim, return_sequences=True)(decoded)\n",
        "\n",
        "sequence_autoencoder = keras.Model(inputs, decoded)\n",
        "encoder = keras.Model(inputs, encoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIwYZloL53bM"
      },
      "source": [
        "original_dim = 28 * 28\n",
        "intermediate_dim = 64\n",
        "latent_dim = 2\n",
        "\n",
        "inputs = keras.Input(shape=(original_dim,))\n",
        "h = layers.Dense(intermediate_dim, activation='relu')(inputs)\n",
        "z_mean = layers.Dense(latent_dim)(h)\n",
        "z_log_sigma = layers.Dense(latent_dim)(h)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IEvWWVS55qi"
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def sampling(args):\n",
        "    z_mean, z_log_sigma = args\n",
        "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim),\n",
        "                              mean=0., stddev=0.1)\n",
        "    return z_mean + K.exp(z_log_sigma) * epsilon\n",
        "\n",
        "z = layers.Lambda(sampling)([z_mean, z_log_sigma])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAlky4b2570H"
      },
      "source": [
        "# Create encoder\n",
        "encoder = keras.Model(inputs, [z_mean, z_log_sigma, z], name='encoder')\n",
        "\n",
        "# Create decoder\n",
        "latent_inputs = keras.Input(shape=(latent_dim,), name='z_sampling')\n",
        "x = layers.Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
        "outputs = layers.Dense(original_dim, activation='sigmoid')(x)\n",
        "decoder = keras.Model(latent_inputs, outputs, name='decoder')\n",
        "\n",
        "# instantiate VAE model\n",
        "outputs = decoder(encoder(inputs)[2])\n",
        "vae = keras.Model(inputs, outputs, name='vae_mlp')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhLPH7_y598x"
      },
      "source": [
        "reconstruction_loss = keras.losses.binary_crossentropy(inputs, outputs)\n",
        "reconstruction_loss *= original_dim\n",
        "kl_loss = 1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma)\n",
        "kl_loss = K.sum(kl_loss, axis=-1)\n",
        "kl_loss *= -0.5\n",
        "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
        "vae.add_loss(vae_loss)\n",
        "vae.compile(optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9WUQQdH5_ur"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "\n",
        "vae.fit(x_train, x_train,\n",
        "        epochs=100,\n",
        "        batch_size=32,\n",
        "        validation_data=(x_test, x_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OOTX_vR6Bil"
      },
      "source": [
        "x_test_encoded = encoder.predict(x_test, batch_size=batch_size)\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test)\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sHm_r4p6Dat"
      },
      "source": [
        "# Display a 2D manifold of the digits\n",
        "n = 15  # figure with 15x15 digits\n",
        "digit_size = 28\n",
        "figure = np.zeros((digit_size * n, digit_size * n))\n",
        "# We will sample n points within [-15, 15] standard deviations\n",
        "grid_x = np.linspace(-15, 15, n)\n",
        "grid_y = np.linspace(-15, 15, n)\n",
        "\n",
        "for i, yi in enumerate(grid_x):\n",
        "    for j, xi in enumerate(grid_y):\n",
        "        z_sample = np.array([[xi, yi]])\n",
        "        x_decoded = decoder.predict(z_sample)\n",
        "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
        "        figure[i * digit_size: (i + 1) * digit_size,\n",
        "               j * digit_size: (j + 1) * digit_size] = digit\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(figure)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cD5sHBXb6Ghn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}