# SureStart
Day 1 (2/8/21): I hope to learn some new methods of supervsed learning to aid in my research. This research uses a large data set gathered from shape characteristics of cancer cells. The goal is to create a predictive model for predicting metastatic behavior using shape characteristics. 

Day 2 (2/9/21): Supervised learning is when you train a computer using a well labeled data set. Unsupervised learning is when you dont need to supervise the model. Rather, you allow the model to make discoveries about the data on its own. Scikit is only responsible for doing the machine learning. It is not capable of visualizing, preparing, or manipulating data. Scikit is built upon libraries that will do these tasks.

Day 3 (2/10/21): Tensors are mathematical objects that generalize scalars, vectors, and matrices to higher dimensions. For example, a tensor can be a single vector, a single matrix, a vector of vectors, or a matrix of matrices. The python code is quite different from my coding experience in Matlab. Tensor calculations do not provide a meaningful output unless prompted. Also, the large tensor containing the mathematical representation of the image was abbreviated with ellipses. 

Day 4 (2/11/21): Here is the dataset that I found: https://www.kaggle.com/c/histopathologic-cancer-detection/overview/description . After doing some research, I found that cancer detection often uses 1-3 layered nueral networks. These layers could be used to calculate and categorize different charactaristics such as size, irregularities, and nuclear to cellular ratios. 

Day 5(2/12/21): This is a notebook that I created which follows the sarcasm detection notebook from the curriculum: https://www.kaggle.com/blaynebanghart/day-5-sarcasm-detection/edit

Day 8(2/15/21): 

Day9 (2/16/21): "Survival of the Best Fit" used data from my candidate selection process, as well as Amazon's data. It created a predicitive model that made hiring decisions based on this data. There was a clear bias in hiring orange over blue people. Certain companies make their decisions based on prior experiences at big name companies. Your CV will immediatley be discarded without a big name company on it. How did these people get experience at those big companies? Some had a connection that may not have been earned, but through family. I know a handful of people that jumped straight into a reputable position at a big company with no experience, simply because their parents work there. How can a machine account for the fact that some people worked part or full-time throughout college and didn't have the time to join 10 different clubs or the funding to take an unpaid internship? Some applicants with difficult financial circumstances will be filtered out because they don't look good on paper. I personally think that these problems cannot be fixed through software engineering, but rather through addressing the bias and values that each company holds. 
